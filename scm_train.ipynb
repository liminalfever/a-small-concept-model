{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c212155a",
   "metadata": {},
   "source": [
    "# Small Concept Model (SCM) Training\n",
    "Here, we train the small concept model for next-concept prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f41ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_cached_embeddings = \"saved_models/train_seq_embeddings.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2405b1e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858b8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"francescoortame/bookcorpus-sorted-100k16x\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cf31c",
   "metadata": {},
   "source": [
    "Create the embeddings to cache them for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b066cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "if load_cached_embeddings is None:\n",
    "    flat_texts = [item for sublist in data[\"slice\"] for item in sublist]\n",
    "    embeddings = encoder.encode(flat_texts, batch_size=32, show_progress_bar=True, convert_to_tensor=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef88f0",
   "metadata": {},
   "source": [
    "Reshape the embeddings to preserve the original sequence structure and create the training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dbfb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "if load_cached_embeddings is None:\n",
    "    reshaped_embeddings = embeddings.contiguous().view(100000, 16, 384)\n",
    "\n",
    "else:\n",
    "    reshaped_embeddings = torch.load(load_cached_embeddings)\n",
    "\n",
    "train_ds = TensorDataset(reshaped_embeddings[:int(0.9*len(reshaped_embeddings))])\n",
    "valid_ds = TensorDataset(reshaped_embeddings[int(0.9*len(reshaped_embeddings)):])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7525e",
   "metadata": {},
   "source": [
    "Finally, define a function to compute the causal mask for autoregressive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c62f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_len: int, device: torch.device):\n",
    "    mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1)\n",
    "    mask = mask.masked_fill(mask == 1, float(\"-inf\"))\n",
    "    mask = mask.masked_fill(mask == 0, float(0.0))\n",
    "    return mask  # [seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b977a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34b141",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8aa7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNet(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super(PreNet, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.scaler_mean = 0.0\n",
    "        self.scaler_std = 1.0\n",
    "\n",
    "    def normalize(self, x):\n",
    "        return (x - self.scaler_mean) / self.scaler_std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class PostNet(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, output_dim: int):\n",
    "        super(PostNet, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "        self.scaler_mean = 0.0\n",
    "        self.scaler_std = 1.0\n",
    "\n",
    "    def denormalize(self, x):\n",
    "        return x * self.scaler_std + self.scaler_mean\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.denormalize(x)\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, num_heads: int, num_layers: int, ff_dim: int, dropout: float = 0.1, max_seq_len: int = 16):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(\n",
    "                d_model=hidden_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=ff_dim,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.pos_encoder = nn.Parameter(torch.zeros(1, max_seq_len, hidden_dim))\n",
    "\n",
    "    def forward(self, x, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, T, hidden_dim]\n",
    "        tgt_mask: square mask of shape [T, T] containing 0 for allowed, -inf for masked.\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # Add positional encoding (broadcasted over batch dimension)\n",
    "        x = x + self.pos_encoder[:, :seq_len, :]\n",
    "        # TransformerDecoderLayer in PyTorch expects input shape [T, B, hidden_dim], so we must transpose.\n",
    "        # Indeed, nn.TransformerDecoderLayer expects (tgt, memory, ...), each of shape [T, B, E].\n",
    "        # We’re using “decoder‐only” (no external memory), so we feed the same x as both tgt and memory.\n",
    "        # That forces it to attend “only to past” via tgt_mask.\n",
    "        x = x.transpose(0, 1)  # now shape [T, B, hidden_dim]\n",
    "        for layer in self.layers:\n",
    "            x = layer(tgt=x, memory=x, tgt_mask=tgt_mask)\n",
    "        x = x.transpose(0, 1)  # back to [B, T, hidden_dim]\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleLCM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_heads: int,\n",
    "        num_layers: int,\n",
    "        ff_dim: int,\n",
    "        output_dim: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super(SimpleLCM, self).__init__()\n",
    "        self.prenet = PreNet(input_dim, hidden_dim)\n",
    "        self.transformer = TransformerDecoder(hidden_dim, num_heads, num_layers, ff_dim, dropout)\n",
    "        self.postnet = PostNet(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, 16, input_dim]\n",
    "        x = self.prenet(x)            # [B, 16, hidden_dim]\n",
    "        causal_mask = generate_causal_mask(x.size(1), device=x.device)  # [16, 16]\n",
    "        x = self.transformer(x, tgt_mask=causal_mask)  # [B, 16, hidden_dim]\n",
    "        x = self.postnet(x)           # [B, 16, output_dim]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279fda0",
   "metadata": {},
   "source": [
    "Initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9cb4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 17218432\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLCM(\n",
    "    input_dim=384,\n",
    "    hidden_dim=512,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    ff_dim=4*512,\n",
    "    output_dim=384,\n",
    "    dropout=.1\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f0891",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84837f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =  5\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5625/5625 [01:44<00:00, 53.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:02<00:00, 263.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 11.31010 | Valid Loss: 14.07859 \n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5625/5625 [01:45<00:00, 53.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:02<00:00, 264.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Train Loss: 0.52025 | Valid Loss: 0.62948 \n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5625/5625 [01:45<00:00, 53.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:02<00:00, 262.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Train Loss: 0.03009 | Valid Loss: 0.11167 \n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5625/5625 [01:44<00:00, 53.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:02<00:00, 262.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Train Loss: 0.00784 | Valid Loss: 0.03316 \n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5625/5625 [01:46<00:00, 52.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:02<00:00, 262.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Train Loss: 0.00487 | Valid Loss: 0.03550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for (batch_input,) in tqdm(train_loader, total=len(train_loader)):\n",
    "        # batch_input: [B, 16, input_dim]\n",
    "        batch_input = batch_input.to(device)  # move to GPU if available\n",
    "        \n",
    "        # (No separate tgt_in/tgt_out since we’re teacher-forcing with the same x for everything.)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1) PreNet → TransformerDecoder → PostNet\n",
    "        # The transformer’s forward handles the causal mask internally.\n",
    "        preds = model(batch_input)  # [B, 16, output_dim]\n",
    "        \n",
    "        # 2) Build a mask to zero out loss at t=0\n",
    "        # We do not care about predicting position 0 (no “previous” vector), so ignore it:\n",
    "        mask = torch.ones_like(batch_input)  # shape [B, 16, input_dim]\n",
    "        mask[:, 0, :] = 0.0  # zero‐weight the t=0 position\n",
    "\n",
    "        # 3) Compute MSE only on positions 1..15\n",
    "        loss = F.mse_loss(preds * mask, batch_input * mask, reduction=\"sum\")\n",
    "        # If you want mean‐per‐element: \n",
    "        #   num_pred_steps = batch_input.size(0) * (batch_input.size(1) - 1)  # B * 15\n",
    "        #   loss = loss / num_pred_steps\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)  # if you used reduction=\"sum\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "\n",
    "        for (batch_input, ) in tqdm(valid_loader, total=len(valid_loader)):\n",
    "            batch_input = batch_input.to(device)\n",
    "            preds = model(batch_input)\n",
    "            mask = torch.ones_like(batch_input)\n",
    "            mask[:, 0, :] = 0.0\n",
    "\n",
    "            loss = F.mse_loss(preds * mask, batch_input * mask, reduction=\"sum\")\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d} | Train Loss: {avg_loss:.5f} | Valid Loss: {avg_val_loss:.5f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c579e7f6",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8c560",
   "metadata": {},
   "source": [
    "### Functions and Preparations for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cfde72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.prenet import PreNet\n",
    "from modules.encdec import get_gpt2_decoder\n",
    "\n",
    "decoder, tokenizer = get_gpt2_decoder()\n",
    "\n",
    "prenet = PreNet(\n",
    "    input_dim=384,\n",
    "    output_dim=768,\n",
    "    bottleneck_dim=128,\n",
    "    prefix_len=20\n",
    ").to(device)\n",
    "\n",
    "prenet.load_state_dict(torch.load(\"saved_models/prenet_prefix_tuning_bookcorpus.pth\", map_location=device))\n",
    "\n",
    "def generative_inference(model, initial_sequence, n_future_steps):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Trained SimpleLCM model.\n",
    "        initial_sequence: Tensor of shape (k, input_dim)\n",
    "        n_future_steps: How many future steps to generate\n",
    "    Returns:\n",
    "        Tensor of shape (k + n_future_steps, input_dim)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    input_seq = initial_sequence.clone().unsqueeze(0).to(device)  # (1, k, input_dim)\n",
    "    generated = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_future_steps):\n",
    "            output = model(input_seq)           # (1, seq_len, output_dim)\n",
    "            next_pred = output[:, -1, :]        # (1, output_dim)\n",
    "            generated.append(next_pred.squeeze(0))  # (output_dim,)\n",
    "            input_seq = torch.cat([input_seq, next_pred.unsqueeze(1)], dim=1)\n",
    "\n",
    "    generated = torch.stack(generated, dim=0)  # (n_future_steps, output_dim)\n",
    "    full_sequence = torch.cat([initial_sequence.to(device), generated], dim=0)  # (k + n_future_steps, input_dim)\n",
    "    return full_sequence\n",
    "\n",
    "def vec_to_text(embedding, decoder, tokenizer, prenet, gen_len=50):\n",
    "    \"\"\"\n",
    "    Given input text, encode it, generate prefix via PreNet, and autoregressively decode output text.\n",
    "    \"\"\"\n",
    "    decoder.eval()\n",
    "    prenet.eval()\n",
    "    with torch.no_grad():\n",
    "        prefix = prenet(embedding.unsqueeze(0))  # (1, prefix_len, model_dim)\n",
    "\n",
    "        generated = prefix  # initial embeddings\n",
    "        generated_ids = []\n",
    "        for _ in range(gen_len):\n",
    "            outputs = decoder(inputs_embeds=generated)\n",
    "            next_logits = outputs.logits[:, -1, :]\n",
    "            next_id = torch.argmax(next_logits, dim=-1).unsqueeze(-1)  # greedy\n",
    "            generated_ids.append(next_id)\n",
    "            next_embed = decoder.transformer.wte(next_id)\n",
    "            generated = torch.cat([generated, next_embed], dim=1)\n",
    "\n",
    "    gen_ids = torch.cat(generated_ids, dim=1)\n",
    "    return tokenizer.decode(gen_ids[0].cpu().numpy(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9fe73a",
   "metadata": {},
   "source": [
    "### Generation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e56b3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " jack , your name is jack . . ''\n",
      "\n",
      "your name is jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack . jack .\n",
      " he said , arriving at the class . . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he\n",
      " he said , arriving at the class . . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he\n",
      " he said , arriving at the class . . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he\n",
      " he said , arriving at the class . . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he said , arriving at the class . . . .\n",
      "\n",
      "'' come , he\n"
     ]
    }
   ],
   "source": [
    "future_steps = 3\n",
    "\n",
    "sentences = [\n",
    "    \"hello, my name is jack.\",\n",
    "    \"he said, as he arrived to class.\"\n",
    "]\n",
    "encoded_sentences = encoder.encode(sentences, convert_to_tensor=True)\n",
    "generated_seq = generative_inference(model, encoded_sentences, n_future_steps=future_steps)\n",
    "\n",
    "for vec in generated_seq:\n",
    "    generated_text = vec_to_text(vec, decoder, tokenizer, prenet, 50)\n",
    "    print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

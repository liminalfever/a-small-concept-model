{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ce1459",
   "metadata": {},
   "source": [
    "## Embedding Space Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94506b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from small_concept_model.inverter import get_encoder\n",
    "from small_concept_model.data import clean_text, SCMDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40788f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"francescoortame/bookcorpus-sorted-100k16x\", split=\"train\")\n",
    "flat_texts = [t for sublist in data[\"slice\"] for t in sublist]\n",
    "flat_texts = [clean_text(t) for t in flat_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd89073",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "embeddings = encoder.encode(flat_texts, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac51416",
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = embeddings.std(dim=0, unbiased=True)\n",
    "\n",
    "sorted_dims = torch.argsort(stds, descending=True)\n",
    "\n",
    "print(\"Top 10 dims by standard deviation:\")\n",
    "for rank, dim_idx in enumerate(sorted_dims[:10]):\n",
    "    print(f\"  rank {rank+1:>2}: dim {dim_idx.item():>3} (std = {stds[dim_idx].item():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cacaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_embeddings = embeddings.contiguous().view(100000, 16, 384)\n",
    "dataset = SCMDataset(reshaped_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc952dfd",
   "metadata": {},
   "source": [
    "## SCM Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8eae7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        T, B, D = x.size()\n",
    "        x = x + self.pe[:T]\n",
    "        return x\n",
    "\n",
    "def generate_causal_mask(sz: int, device: torch.device) -> torch.Tensor:\n",
    "    mask = torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)\n",
    "    return mask.to(device)\n",
    "\n",
    "\n",
    "class SmallConceptModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int = 384,\n",
    "        embed_dim: int = 384,\n",
    "        nhead: int = 8,\n",
    "        num_layers: int = 6,\n",
    "        dim_feedforward: int = 384 * 4,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_len: int = 64\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.input_proj = nn.Linear(embed_dim, d_model, bias=True)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_seq_len)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.output_proj = nn.Linear(d_model, embed_dim, bias=True)\n",
    "        self.register_buffer('dummy_mask', torch.zeros(1))\n",
    "\n",
    "    def forward(self, input_seq: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, D = input_seq.shape\n",
    "        device = input_seq.device\n",
    "        x = input_seq.permute(1, 0, 2)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        causal_mask = generate_causal_mask(T, device=device)\n",
    "        encoded = self.transformer_encoder(x, mask=causal_mask)\n",
    "        output = self.output_proj(encoded)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db03c43",
   "metadata": {},
   "source": [
    "#### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "00f8dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = embeddings.std(dim=0, unbiased=False)\n",
    "sigma_min = stds.min().item()\n",
    "sigma_max = stds.max().item()\n",
    "\n",
    "if sigma_max - sigma_min < 1e-12:\n",
    "    weights = torch.ones_like(stds) * 1e-3\n",
    "else:\n",
    "    weights = (stds - sigma_min) / (sigma_max - sigma_min)\n",
    "    epsilon = 1e-6\n",
    "    weights = torch.clamp(weights, min=epsilon)\n",
    "\n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, weight_vector: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.register_buffer('w', weight_vector.view(1, -1))\n",
    "\n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        if predictions.shape != targets.shape:\n",
    "            raise ValueError(f\"predictions and targets must have same shape. \"\n",
    "                             f\"Got {predictions.shape} vs {targets.shape}.\")\n",
    "        se = (predictions - targets) ** 2\n",
    "        weighted_se = se * self.w \n",
    "        return weighted_se.mean()\n",
    "    \n",
    "\n",
    "class MSELossWithAvgPenalty(nn.Module):\n",
    "    def __init__(self, avg_vector: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.register_buffer('avg', avg_vector)\n",
    "    \n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        if predictions.shape != targets.shape:\n",
    "            raise ValueError(f\"predictions and targets must have same shape. \"\n",
    "                             f\"Got {predictions.shape} vs {targets.shape}.\")\n",
    "        \n",
    "        B, T, D = predictions.shape\n",
    "\n",
    "        pred_flat = predictions.reshape(-1, D)                                 # [B*T, 384]\n",
    "        pred_flat_norm = F.normalize(pred_flat, p=2, dim=1)           # [B*T, 384]\n",
    "        avg_expanded = self.avg.unsqueeze(0).expand(pred_flat_norm.size(0), -1)\n",
    "        cos_sims = (pred_flat_norm * avg_expanded).sum(dim=1)         # [B*T]\n",
    "        batch_avg_cos_sim = cos_sims.mean().item()\n",
    "        \n",
    "        se = (predictions - targets) ** 2\n",
    "\n",
    "        loss = se.mean() + batch_avg_cos_sim\n",
    "\n",
    "        return loss\n",
    "\n",
    "class AntiAverageLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function that INCREASES when predictions get closer to the average embedding.\n",
    "    This will force the model to predict anything BUT the average.\n",
    "    If your model still collapses with this loss, there's definitely a bug.\n",
    "    \"\"\"\n",
    "    def __init__(self, avg_embedding, penalty_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('avg_embedding', avg_embedding)\n",
    "        self.penalty_weight = penalty_weight\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # predictions: [B, T, D] or [B*T, D]\n",
    "        # targets: [B, T, D] or [B*T, D] \n",
    "        \n",
    "        # Flatten if needed\n",
    "        if predictions.dim() == 3:\n",
    "            pred_flat = predictions.reshape(-1, predictions.size(-1))\n",
    "            tgt_flat = targets.reshape(-1, targets.size(-1))\n",
    "        else:\n",
    "            pred_flat = predictions\n",
    "            tgt_flat = targets\n",
    "        \n",
    "        # Normalize vectors\n",
    "        pred_norm = F.normalize(pred_flat, p=2, dim=1)\n",
    "        avg_norm = F.normalize(self.avg_embedding, p=2, dim=0)\n",
    "        \n",
    "        # Cosine similarity with average (higher = more similar to average)\n",
    "        cos_sim_with_avg = torch.mm(pred_norm, avg_norm.unsqueeze(1)).squeeze()\n",
    "        \n",
    "        # Convert to penalty: higher similarity = higher loss\n",
    "        # Use sigmoid to bound the penalty and make it smooth\n",
    "        avg_penalty = torch.sigmoid(cos_sim_with_avg * 5)  # Scale factor makes it more sensitive\n",
    "        \n",
    "        # Main loss: encourage predictions to match targets\n",
    "        main_loss = 1 - F.cosine_similarity(pred_flat, tgt_flat, dim=1)\n",
    "        \n",
    "        # Combined loss: minimize target error + maximize distance from average\n",
    "        total_loss = main_loss.mean() + self.penalty_weight * avg_penalty.mean()\n",
    "        \n",
    "        return total_loss, main_loss.mean()\n",
    "        \n",
    "\n",
    "class CosineSimilarityLoss(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, predictions: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        if predictions.shape != targets.shape:\n",
    "            raise ValueError(\n",
    "                f\"predictions and targets must have same shape. \"\n",
    "                f\"Got {predictions.shape} vs {targets.shape}.\"\n",
    "            )\n",
    "\n",
    "        cos_sim = F.cosine_similarity(predictions, targets, dim=-1, eps=self.eps)\n",
    "        loss = 1.0 - cos_sim\n",
    "        return loss.mean()\n",
    "    \n",
    "def combined_loss(pred, target, alpha=0.7):\n",
    "    mse = F.mse_loss(pred, target)\n",
    "    cosine = 1 - F.cosine_similarity(pred, target, dim=-1).mean()\n",
    "    return alpha * mse + (1 - alpha) * cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb23e7",
   "metadata": {},
   "source": [
    "I suspect the model is always predicting the mean vector, let's check if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aa8ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embedding = embeddings.mean(dim=0)\n",
    "avg_embedding = avg_embedding / avg_embedding.norm(p=2, dim=0)\n",
    "avg_embedding = avg_embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "79bf5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "model = SmallConceptModel(\n",
    "    d_model=512,\n",
    "    embed_dim=384,\n",
    "    nhead=4,\n",
    "    num_layers=3,\n",
    "    dim_feedforward=512*4,\n",
    "    dropout=0.0,\n",
    "    max_seq_len=dataset.seq_len  # so positional encoding covers full length\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "#loss_fn = WeightedMSELoss(weights.to(device))\n",
    "#loss_fn = nn.MSELoss()\n",
    "#loss_fn = CosineSimilarityLoss()\n",
    "#loss_fn = MSELossWithAvgPenalty(avg_embedding)\n",
    "#loss_fn = MSELossWithAvgPenalty(avg_embedding)\n",
    "loss_fn = AntiAverageLoss(avg_embedding, 0.35)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) 20 | Loss = 0.953035 | Main Loss = 0.605389| Pred Sim = 0.998983 | True Sim = 0.394653\n",
      "(Epoch 1) 40 | Loss = 0.961489 | Main Loss = 0.613842| Pred Sim = 0.999051 | True Sim = 0.386534\n",
      "(Epoch 1) 60 | Loss = 0.955100 | Main Loss = 0.607454| Pred Sim = 0.999026 | True Sim = 0.392910\n",
      "(Epoch 1) 80 | Loss = 0.959364 | Main Loss = 0.611714| Pred Sim = 0.999357 | True Sim = 0.388550\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[278]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m avg_expanded = avg_embedding.unsqueeze(\u001b[32m0\u001b[39m).expand(pred_flat_norm.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     29\u001b[39m cos_sims = (pred_flat_norm * avg_expanded).sum(dim=\u001b[32m1\u001b[39m)         \u001b[38;5;66;03m# [B*T]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m batch_avg_cos_sim = \u001b[43mcos_sims\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m tgt_flat = target_batch.reshape(-\u001b[32m1\u001b[39m, D)                                 \u001b[38;5;66;03m# [B*T, 384]\u001b[39;00m\n\u001b[32m     33\u001b[39m tgt_flat_norm = F.normalize(tgt_flat, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        model.train()\n",
    "        # input_batch, target_batch: [B, T, D]\n",
    "        input_batch = input_batch.to(device)      # [B, T, 384]\n",
    "        target_batch = target_batch.to(device)    # [B, T, 384]\n",
    "\n",
    "        noise_scale = 0.01\n",
    "\n",
    "        noise = torch.randn_like(input_batch) * noise_scale\n",
    "        input_batch = input_batch + noise\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(input_batch)                # preds.shape = [B, T, 384]\n",
    "        loss, main_loss = loss_fn(preds, target_batch)       # compare preds[:, t, :] to target[:, t, :]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            B, T, D = preds.shape\n",
    "\n",
    "            pred_flat = preds.reshape(-1, D)                                 # [B*T, 384]\n",
    "            pred_flat_norm = F.normalize(pred_flat, p=2, dim=1)           # [B*T, 384]\n",
    "            avg_expanded = avg_embedding.unsqueeze(0).expand(pred_flat_norm.size(0), -1)\n",
    "            cos_sims = (pred_flat_norm * avg_expanded).sum(dim=1)         # [B*T]\n",
    "            batch_avg_cos_sim = cos_sims.mean().item()\n",
    "\n",
    "            tgt_flat = target_batch.reshape(-1, D)                                 # [B*T, 384]\n",
    "            tgt_flat_norm = F.normalize(tgt_flat, p=2, dim=1)\n",
    "            cos_sims = (tgt_flat_norm * avg_expanded).sum(dim=1)         # [B*T]\n",
    "            tgt_batch_avg_cos_sim = cos_sims.mean().item()\n",
    "\n",
    "        if (idx + 1) % 20 == 0:\n",
    "            print(f\"(Epoch {epoch+1}) {idx+1} | Loss = {loss.item():.6f} | Main Loss = {main_loss.item():.6f}| Pred Sim = {batch_avg_cos_sim:.6f} | True Sim = {tgt_batch_avg_cos_sim:.6f}\")\n",
    "    print(f\"*** Epoch {epoch+1}/{num_epochs} — Loss = {loss.item():.6f} ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c6b1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from small_concept_model.model import SmallConceptModel\n",
    "from small_concept_model.pipeline import Pipeline\n",
    "from small_concept_model.inverter import PreNet, Inverter, get_encoder, get_gpt2_decoder\n",
    "from small_concept_model.train import train_scm, train_inverter\n",
    "from small_concept_model.data import get_bookcorpus_scm, get_bookcorpus_inverter\n",
    "from small_concept_model.auto import build_scm, build_inverter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4deb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_configs = {\n",
    "    \"d_model\": 384,\n",
    "    \"d_embed\": 384,\n",
    "    \"d_ff\": 4 * 384,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 16\n",
    "}\n",
    "\n",
    "prenet_configs = {\n",
    "    \"input_dim\": 384,\n",
    "    \"output_dim\": 768,\n",
    "    \"rank\": 128,\n",
    "    \"prefix_len\": 20,\n",
    "}\n",
    "\n",
    "train_configs = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64956b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "prenet = PreNet(**prenet_configs).to(device)\n",
    "decoder, tokenizer = get_gpt2_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_bookcorpus_inverter(\n",
    "    encoder, tokenizer, max_target_len=64, embed_batch_size=256, sample=0.1, clean=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fbcbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inverter(prenet, decoder, tokenizer, data, **train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66143316",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prenet.state_dict(), \"saved_models/prenet/prenet_100k_good.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae48611",
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet.load_state_dict(torch.load(\"saved_models/prenet/prenet_100k_good.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = Inverter(prenet, decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\\\"You were never the problem,\\\" he said, \\\"and you know it\\\".\"\n",
    "\n",
    "vec = encoder.encode(sample_text, convert_to_tensor=True)\n",
    "inverter.invert(\n",
    "    vec, max_len=50, temperature=0.4, repetition_penalty=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d76eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=\"cuda\")\n",
    "dataset = get_bookcorpus_scm(encoder, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e1207",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_x = load_dataset(\"francescoortame/bookcorpus-rand-1M\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_x[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from small_concept_model.utils import clean_text\n",
    "\n",
    "clean_texts = []\n",
    "\n",
    "for t in tqdm(texts, total=len(texts)):\n",
    "    clean_texts.append(clean_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts = [t + tokenizer.eos_token for t in clean_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts[237920]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c2863",
   "metadata": {},
   "source": [
    "# SCM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "dataset = get_bookcorpus_scm(\n",
    "    encoder,\n",
    "    embed_batch_size=128,\n",
    "    clean=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallConceptModel(**scm_configs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scm(model, dataset, **train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet = PreNet(**prenet_configs).to(device)\n",
    "prenet.load_state_dict(torch.load(\"saved_models/prenet/prenet_100k_good.pth\", map_location=device))\n",
    "\n",
    "decoder, tokenizer = get_gpt2_decoder()\n",
    "inverter = Inverter(prenet, decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(encoder, model, inverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Lexi stretched her arms.',\n",
    "    'She heard the door open, and soft voices echoed down the hall toward her.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter.invert(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513818c",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")\n",
    "inverter = build_inverter(\"paraphrase_multilingual\")\n",
    "pipe = Pipeline(encoder, model, inverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00616434",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'he asked her if she was hungry.',\n",
    "    'she never heard that before.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2dbc1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Standard sinusoidal positional encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: Optional[int] = 128):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        denominator = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * denominator)\n",
    "        pe[:, 1::2] = torch.cos(position * denominator)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "\n",
    "class InputProj(nn.Module):\n",
    "    def __init__(self, d_embed, d_model, scaler_mean, scaler_std):\n",
    "        super().__init__()\n",
    "        # scaler_mean, scaler_std: each is a [d_embed]-shaped tensor\n",
    "        self.register_buffer(\"mean\", scaler_mean)   # shape: [d_embed]\n",
    "        self.register_buffer(\"std\",  scaler_std)    # shape: [d_embed]\n",
    "        self.linear = nn.Linear(d_embed, d_model)\n",
    "\n",
    "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_embed]\n",
    "        # subtract/scale each dimension separately\n",
    "        return (x - self.mean.unsqueeze(0).unsqueeze(0)) / self.std.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.normalize(x)            # [B, T, d_embed] → zero‐centered (per‐dim)\n",
    "        return self.linear(x)            # → [B, T, d_model]\n",
    "\n",
    "\n",
    "\n",
    "class OutputProj(nn.Module):\n",
    "    def __init__(self, d_model, d_embed, scaler_mean, scaler_std):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", scaler_mean)   # [d_embed]\n",
    "        self.register_buffer(\"std\",  scaler_std)    # [d_embed]\n",
    "        self.linear = nn.Linear(d_model, d_embed)\n",
    "\n",
    "    def denormalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_embed] in “normalized space”\n",
    "        return x * self.std.unsqueeze(0).unsqueeze(0) + self.mean.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)             # [B, T, d_embed]\n",
    "        return self.denormalize(x)     # map back to “real” embedding distribution\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer encoder with causal masking.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_ff: int,\n",
    "        n_heads: Optional[int] = 4,\n",
    "        n_layers: Optional[int] = 3,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer, num_layers=n_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _, seq_len, _ = x.size()\n",
    "        bool_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool), diagonal=1)\n",
    "        bool_mask = bool_mask.to(x.device)\n",
    "        return self.transformer(x, bool_mask)\n",
    "\n",
    "\n",
    "class SmallConceptModel(nn.Module):\n",
    "    \"\"\"Autoregressive transformer-based concept model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_embed: int,\n",
    "        d_ff: int,\n",
    "        n_heads: Optional[int] = 4,\n",
    "        n_layers: Optional[int] = 3,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "        max_seq_len: Optional[int] = 128,\n",
    "        scaler_mean: Optional[float] = 0.0,\n",
    "        scaler_std: Optional[float] = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = InputProj(d_embed, d_model, scaler_mean, scaler_std)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_len)\n",
    "        self.transformer = Transformer(d_model, d_ff, n_heads, n_layers, dropout)\n",
    "        self.output_projection = OutputProj(d_model, d_embed, scaler_mean, scaler_std)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_projection(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.output_projection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "from small_concept_model.data import InverterDataset, SCMDataset\n",
    "from small_concept_model.inverter import PreNet\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from small_concept_model.model import SmallConceptModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def combined_mse_cosine_loss(\n",
    "        preds: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        lambda_cos: float = 0.5\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    preds:   (B, L, D_embed)  predicted embeddings\n",
    "    targets: (B, L, D_embed)  ground-truth embeddings\n",
    "    lambda_cos: weight on the (1 - cosine) term. \n",
    "                Total loss = lambda_cos * (1 - cos) + (1-lambda_cos) * MSE.\n",
    "\n",
    "    Returns: mean loss over all B * L elements (a scalar).\n",
    "    \"\"\"\n",
    "    # 1) Compute MSE term (per-coordinate)\n",
    "    mse_per_coord = F.mse_loss(preds, targets, reduction=\"none\")  # shape (B, L, D_embed)\n",
    "    mse_per_vector = mse_per_coord.mean(dim=-1)                     # shape (B, L), avg over D_embed\n",
    "    mse_term = mse_per_vector.mean()                                # scalar: avg over B * L\n",
    "\n",
    "    # 2) Compute cosine term\n",
    "    #    Flatten B*L so we can use F.cosine_similarity on shape ((B*L), D_embed)\n",
    "    B, L, D = preds.shape\n",
    "    preds_flat   = preds.view(B * L, D)    # shape (B*L, D_embed)\n",
    "    targets_flat = targets.view(B * L, D)  # shape (B*L, D_embed)\n",
    "\n",
    "    #    cosine_similarity returns shape (B*L,), values in [-1, +1]\n",
    "    cos_sim = F.cosine_similarity(preds_flat, targets_flat, dim=-1, eps=1e-8)  # (B*L,)\n",
    "    cos_dist = 1.0 - cos_sim                                                   # (B*L,)\n",
    "\n",
    "    cosine_term = cos_dist.mean()  # scalar\n",
    "\n",
    "    # 3) Combine\n",
    "    loss = lambda_cos * cosine_term + (1.0 - lambda_cos) * mse_term\n",
    "    return loss\n",
    "\n",
    "def train_scm(\n",
    "    model: SmallConceptModel,\n",
    "    train_dataset: SCMDataset,\n",
    "    lr: Optional[float] = 1e-3,\n",
    "    weight_decay: Optional[float] = 1e-2,\n",
    "    batch_size: Optional[int] = 32,\n",
    "    num_epochs: Optional[int] = 1,\n",
    "    schedule_length: int = 3,   # # of epochs to go from ε=0 → ε_max\n",
    "    eps_max: float = 0.5,\n",
    "):\n",
    "    \"\"\"Train the SCM for next-embedding prediction.\"\"\"\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    mse_loss = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for batch_idx, (input_seq, target_seq) in enumerate(train_loader):\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            \n",
    "            output = model(input_seq)\n",
    "            loss = combined_mse_cosine_loss(output, target_seq, lambda_cos=1e-9)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch [{epoch}/{num_epochs}]  \"\n",
    "                    f\"Batch [{batch_idx+1}/{len(train_loader)}]  \"\n",
    "                    f\"Loss: {loss.item():.6f}\"\n",
    "                )\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / n_batches\n",
    "        print(f\"*** Epoch {epoch} Complete.  Avg Loss = {avg_epoch_loss:.6f} ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [dataset[i][0] for i in range(len(dataset))]\n",
    "all_embeddings = torch.stack(tensor_list)\n",
    "\n",
    "flat = all_embeddings.view(-1, 384)        # → [1_600_000, d_embed]\n",
    "mean_vec = flat.mean(dim=0)                    # [d_embed]\n",
    "std_vec  = flat.std(dim=0, unbiased=False)\n",
    "\n",
    "scm_configs = {\n",
    "    \"d_model\": 384,\n",
    "    \"d_embed\": 384,\n",
    "    \"d_ff\": 4 * 384,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 16,\n",
    "    \"scaler_mean\": mean_vec,\n",
    "    \"scaler_std\": std_vec\n",
    "}\n",
    "\n",
    "model = SmallConceptModel(**scm_configs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scm(\n",
    "    model,\n",
    "    dataset,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0,\n",
    "    batch_size=128,\n",
    "    num_epochs=3,\n",
    "    schedule_length=3,\n",
    "    eps_max=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add108c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'he asked her if she was hungry.',\n",
    "    'she never heard that before.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [dataset[i][0] for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack(tensor_list)\n",
    "d = c.view(-1, 384)\n",
    "\n",
    "global_mean = d.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift targets:\n",
    "X = c[:, :14, :]   # your input windows (ground truth)\n",
    "Y = c[:, 1:, :]    # “true” next embeddings\n",
    "\n",
    "n_total = float(Y.numel())\n",
    "baseline_mse = ((Y - global_mean.unsqueeze(0).unsqueeze(0))**2).sum() / n_total\n",
    "print(\"Mean-predictor MSE:\", baseline_mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.view(-1, 384).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

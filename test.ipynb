{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d170b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from small_concept_model.model import SmallConceptModel\n",
    "from small_concept_model.pipeline import Pipeline\n",
    "from small_concept_model.inverter import PreNet, Inverter, get_encoder, get_gpt2_decoder\n",
    "from small_concept_model.train import train_scm, train_inverter\n",
    "from small_concept_model.data import get_bookcorpus_scm, get_bookcorpus_inverter\n",
    "from small_concept_model.auto import build_scm, build_inverter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b4deb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_configs = {\n",
    "    \"d_model\": 384,\n",
    "    \"d_embed\": 384,\n",
    "    \"d_ff\": 4 * 384,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 16\n",
    "}\n",
    "\n",
    "prenet_configs = {\n",
    "    \"input_dim\": 384,\n",
    "    \"output_dim\": 768,\n",
    "    \"rank\": 128,\n",
    "    \"prefix_len\": 20,\n",
    "}\n",
    "\n",
    "train_configs = {\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 0,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64956b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "prenet = PreNet(**prenet_configs).to(device)\n",
    "decoder, tokenizer = get_gpt2_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df5336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning texts...\n",
      "Tokenizing the texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:09<00:00, 41.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_bookcorpus_inverter(\n",
    "    encoder, tokenizer, max_target_len=64, embed_batch_size=256, sample=0.1, clean=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27fbcbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1563/1563 [05:16<00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch 0 Complete.  Avg Loss = 2.259933 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_inverter(prenet, decoder, tokenizer, data, **train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66143316",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(prenet.state_dict(), \"saved_models/prenet/prenet_100k_good.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eae48611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prenet.load_state_dict(torch.load(\"saved_models/prenet/prenet_100k_good.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc1b6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverter = Inverter(prenet, decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "93f2fd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You know, you never knew the problem,\" he said.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"\\\"You were never the problem,\\\" he said, \\\"and you know it\\\".\"\n",
    "\n",
    "vec = encoder.encode(sample_text, convert_to_tensor=True)\n",
    "inverter.invert(\n",
    "    vec, max_len=50, temperature=0.4, repetition_penalty=1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d76eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babbecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [10:46<00:00, 77.31it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=\"cuda\")\n",
    "dataset = get_bookcorpus_scm(encoder, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e1207",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6780b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_x = load_dataset(\"francescoortame/bookcorpus-rand-1M\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daa9dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_x[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78cb59ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:05<00:00, 176557.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from small_concept_model.utils import clean_text\n",
    "\n",
    "clean_texts = []\n",
    "\n",
    "for t in tqdm(texts, total=len(texts)):\n",
    "    clean_texts.append(clean_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0b3a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts = [t + tokenizer.eos_token for t in clean_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e916776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"What shall we do to commemorate our first day of coupledom?\"<|endoftext|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_texts[237920]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c2863",
   "metadata": {},
   "source": [
    "# SCM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02e45c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12500/12500 [02:45<00:00, 75.42it/s]\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "dataset = get_bookcorpus_scm(\n",
    "    encoder,\n",
    "    embed_batch_size=128,\n",
    "    clean=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e4ea4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallConceptModel(**scm_configs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6815cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1]  Batch [100/1563]  Loss: 0.053620\n",
      "Epoch [1/1]  Batch [200/1563]  Loss: 0.049489\n",
      "Epoch [1/1]  Batch [300/1563]  Loss: 0.047784\n",
      "Epoch [1/1]  Batch [400/1563]  Loss: 0.046954\n",
      "Epoch [1/1]  Batch [500/1563]  Loss: 0.047889\n",
      "Epoch [1/1]  Batch [600/1563]  Loss: 0.046675\n",
      "Epoch [1/1]  Batch [700/1563]  Loss: 0.047618\n",
      "Epoch [1/1]  Batch [800/1563]  Loss: 0.046970\n",
      "Epoch [1/1]  Batch [900/1563]  Loss: 0.046868\n",
      "Epoch [1/1]  Batch [1000/1563]  Loss: 0.047154\n",
      "Epoch [1/1]  Batch [1100/1563]  Loss: 0.046410\n",
      "Epoch [1/1]  Batch [1200/1563]  Loss: 0.046313\n",
      "Epoch [1/1]  Batch [1300/1563]  Loss: 0.046832\n",
      "Epoch [1/1]  Batch [1400/1563]  Loss: 0.046077\n",
      "Epoch [1/1]  Batch [1500/1563]  Loss: 0.046274\n",
      "*** Epoch 1 Complete.  Avg Loss = 0.048678 ***\n"
     ]
    }
   ],
   "source": [
    "train_scm(model, dataset, **train_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7c9aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prenet = PreNet(**prenet_configs).to(device)\n",
    "prenet.load_state_dict(torch.load(\"saved_models/prenet/prenet_100k_good.pth\", map_location=device))\n",
    "\n",
    "decoder, tokenizer = get_gpt2_decoder()\n",
    "inverter = Inverter(prenet, decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e02dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(encoder, model, inverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee83a00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elle stretched, tugging her arms.',\n",
       " ' she heard the quiet of the room, the soft footsteps of the door.',\n",
       " 'and then she glanced at the floor, her eyes wide with confusion.',\n",
       " 'and then she glanced at the floor, her eyes wide with confusion.',\n",
       " 'and then she glanced at the floor, and then at the floor, and then at the floor, and then at the floor, and then at the',\n",
       " 'and then she glanced at the floor, and then at the man she had just met.',\n",
       " 'and then she glanced at her husband, who was staring at her with a confused expression.']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'Lexi stretched her arms.',\n",
    "    'She heard the door open, and soft voices echoed down the hall toward her.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbe5255d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mike, who had been standing in the doorway, glanced at her, then turned to the other side of the room, where she was standing.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverter.invert(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513818c",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af3c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "inverter = build_inverter(\"paraphrase_multilingual\")\n",
    "pipe = Pipeline(encoder, model, inverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00616434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" she asked him if he was hungry . '' he replied . '' she asked him if he was hungry . '' she asked him if he was hungry .\",\n",
       " \" she never heard that before . '\\n\\nBut she never heard that before . '\\n\\nBut she never heard that before . '\\n\\nBut\",\n",
       " \" she said , and then she said , '' yes , she should be able to talk about it . '' . '' she said , and then she said\",\n",
       " \" she said , and then she gave him a small smile . '' she said , and then she ate the rest of the food . '' she said ,\",\n",
       " \" she was glad to have him as her companion , but she knew that she would have to eat some of the food she had been given . '' she\",\n",
       " \" she was glad to have been able to eat the food , but she was not sure how to describe it . '' she said , her voice soft and\",\n",
       " ' she was glad to have been able to eat the food , but she was also pleased to know that she was not the only one who had been pleased']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'he asked her if she was hungry.',\n",
    "    'she never heard that before.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2dbc1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3bb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Standard sinusoidal positional encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: Optional[int] = 128):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        denominator = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * denominator)\n",
    "        pe[:, 1::2] = torch.cos(position * denominator)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "\n",
    "class InputProj(nn.Module):\n",
    "    def __init__(self, d_embed, d_model, scaler_mean, scaler_std):\n",
    "        super().__init__()\n",
    "        # scaler_mean, scaler_std: each is a [d_embed]-shaped tensor\n",
    "        self.register_buffer(\"mean\", scaler_mean)   # shape: [d_embed]\n",
    "        self.register_buffer(\"std\",  scaler_std)    # shape: [d_embed]\n",
    "        self.linear = nn.Linear(d_embed, d_model)\n",
    "\n",
    "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_embed]\n",
    "        # subtract/scale each dimension separately\n",
    "        return (x - self.mean.unsqueeze(0).unsqueeze(0)) / self.std.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.normalize(x)            # [B, T, d_embed] → zero‐centered (per‐dim)\n",
    "        return self.linear(x)            # → [B, T, d_model]\n",
    "\n",
    "\n",
    "\n",
    "class OutputProj(nn.Module):\n",
    "    def __init__(self, d_model, d_embed, scaler_mean, scaler_std):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mean\", scaler_mean)   # [d_embed]\n",
    "        self.register_buffer(\"std\",  scaler_std)    # [d_embed]\n",
    "        self.linear = nn.Linear(d_model, d_embed)\n",
    "\n",
    "    def denormalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, d_embed] in “normalized space”\n",
    "        return x * self.std.unsqueeze(0).unsqueeze(0) + self.mean.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear(x)             # [B, T, d_embed]\n",
    "        return self.denormalize(x)     # map back to “real” embedding distribution\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer encoder with causal masking.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_ff: int,\n",
    "        n_heads: Optional[int] = 4,\n",
    "        n_layers: Optional[int] = 3,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer, num_layers=n_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _, seq_len, _ = x.size()\n",
    "        bool_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool), diagonal=1)\n",
    "        bool_mask = bool_mask.to(x.device)\n",
    "        return self.transformer(x, bool_mask)\n",
    "\n",
    "\n",
    "class SmallConceptModel(nn.Module):\n",
    "    \"\"\"Autoregressive transformer-based concept model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_embed: int,\n",
    "        d_ff: int,\n",
    "        n_heads: Optional[int] = 4,\n",
    "        n_layers: Optional[int] = 3,\n",
    "        dropout: Optional[float] = 0.1,\n",
    "        max_seq_len: Optional[int] = 128,\n",
    "        scaler_mean: Optional[float] = 0.0,\n",
    "        scaler_std: Optional[float] = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = InputProj(d_embed, d_model, scaler_mean, scaler_std)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_len)\n",
    "        self.transformer = Transformer(d_model, d_ff, n_heads, n_layers, dropout)\n",
    "        self.output_projection = OutputProj(d_model, d_embed, scaler_mean, scaler_std)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.input_projection(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.output_projection(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1191f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional\n",
    "from small_concept_model.data import InverterDataset, SCMDataset\n",
    "from small_concept_model.inverter import PreNet\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from small_concept_model.model import SmallConceptModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def combined_mse_cosine_loss(\n",
    "        preds: torch.Tensor,\n",
    "        targets: torch.Tensor,\n",
    "        lambda_cos: float = 0.5\n",
    "    ) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    preds:   (B, L, D_embed)  predicted embeddings\n",
    "    targets: (B, L, D_embed)  ground-truth embeddings\n",
    "    lambda_cos: weight on the (1 - cosine) term. \n",
    "                Total loss = lambda_cos * (1 - cos) + (1-lambda_cos) * MSE.\n",
    "\n",
    "    Returns: mean loss over all B * L elements (a scalar).\n",
    "    \"\"\"\n",
    "    # 1) Compute MSE term (per-coordinate)\n",
    "    mse_per_coord = F.mse_loss(preds, targets, reduction=\"none\")  # shape (B, L, D_embed)\n",
    "    mse_per_vector = mse_per_coord.mean(dim=-1)                     # shape (B, L), avg over D_embed\n",
    "    mse_term = mse_per_vector.mean()                                # scalar: avg over B * L\n",
    "\n",
    "    # 2) Compute cosine term\n",
    "    #    Flatten B*L so we can use F.cosine_similarity on shape ((B*L), D_embed)\n",
    "    B, L, D = preds.shape\n",
    "    preds_flat   = preds.view(B * L, D)    # shape (B*L, D_embed)\n",
    "    targets_flat = targets.view(B * L, D)  # shape (B*L, D_embed)\n",
    "\n",
    "    #    cosine_similarity returns shape (B*L,), values in [-1, +1]\n",
    "    cos_sim = F.cosine_similarity(preds_flat, targets_flat, dim=-1, eps=1e-8)  # (B*L,)\n",
    "    cos_dist = 1.0 - cos_sim                                                   # (B*L,)\n",
    "\n",
    "    cosine_term = cos_dist.mean()  # scalar\n",
    "\n",
    "    # 3) Combine\n",
    "    loss = lambda_cos * cosine_term + (1.0 - lambda_cos) * mse_term\n",
    "    return loss\n",
    "\n",
    "def train_scm(\n",
    "    model: SmallConceptModel,\n",
    "    train_dataset: SCMDataset,\n",
    "    lr: Optional[float] = 1e-3,\n",
    "    weight_decay: Optional[float] = 1e-2,\n",
    "    batch_size: Optional[int] = 32,\n",
    "    num_epochs: Optional[int] = 1,\n",
    "    schedule_length: int = 3,   # # of epochs to go from ε=0 → ε_max\n",
    "    eps_max: float = 0.5,\n",
    "):\n",
    "    \"\"\"Train the SCM for next-embedding prediction.\"\"\"\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    mse_loss = torch.nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for batch_idx, (input_seq, target_seq) in enumerate(train_loader):\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "            \n",
    "            output = model(input_seq)\n",
    "            loss = combined_mse_cosine_loss(output, target_seq, lambda_cos=1e-9)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch [{epoch}/{num_epochs}]  \"\n",
    "                    f\"Batch [{batch_idx+1}/{len(train_loader)}]  \"\n",
    "                    f\"Loss: {loss.item():.6f}\"\n",
    "                )\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / n_batches\n",
    "        print(f\"*** Epoch {epoch} Complete.  Avg Loss = {avg_epoch_loss:.6f} ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce0a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/fo-a100-24c/code/Users/francesco.ortame/a-small-concept-model/small_concept_model/model.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"mean\", torch.tensor(scaler_mean))\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/fo-a100-24c/code/Users/francesco.ortame/a-small-concept-model/small_concept_model/model.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"std\", torch.tensor(scaler_std))\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/fo-a100-24c/code/Users/francesco.ortame/a-small-concept-model/small_concept_model/model.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"mean\", torch.tensor(scaler_mean))\n",
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/fo-a100-24c/code/Users/francesco.ortame/a-small-concept-model/small_concept_model/model.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"std\", torch.tensor(scaler_std))\n"
     ]
    }
   ],
   "source": [
    "tensor_list = [dataset[i][0] for i in range(len(dataset))]\n",
    "all_embeddings = torch.stack(tensor_list)\n",
    "\n",
    "flat = all_embeddings.view(-1, 384)        # → [1_600_000, d_embed]\n",
    "mean_vec = flat.mean(dim=0)                    # [d_embed]\n",
    "std_vec  = flat.std(dim=0, unbiased=False)\n",
    "\n",
    "scm_configs = {\n",
    "    \"d_model\": 384,\n",
    "    \"d_embed\": 384,\n",
    "    \"d_ff\": 4 * 384,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 16,\n",
    "    \"scaler_mean\": mean_vec,\n",
    "    \"scaler_std\": std_vec\n",
    "}\n",
    "\n",
    "model = SmallConceptModel(**scm_configs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8529ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]  Batch [100/782]  Loss: 0.046695\n",
      "Epoch [1/3]  Batch [200/782]  Loss: 0.046569\n",
      "Epoch [1/3]  Batch [300/782]  Loss: 0.046447\n",
      "Epoch [1/3]  Batch [400/782]  Loss: 0.046278\n",
      "Epoch [1/3]  Batch [500/782]  Loss: 0.046586\n",
      "Epoch [1/3]  Batch [600/782]  Loss: 0.046114\n",
      "Epoch [1/3]  Batch [700/782]  Loss: 0.045864\n",
      "*** Epoch 1 Complete.  Avg Loss = 0.046646 ***\n",
      "Epoch [2/3]  Batch [100/782]  Loss: 0.045720\n",
      "Epoch [2/3]  Batch [200/782]  Loss: 0.046038\n",
      "Epoch [2/3]  Batch [300/782]  Loss: 0.046060\n",
      "Epoch [2/3]  Batch [400/782]  Loss: 0.046071\n",
      "Epoch [2/3]  Batch [500/782]  Loss: 0.046395\n",
      "Epoch [2/3]  Batch [600/782]  Loss: 0.045955\n",
      "Epoch [2/3]  Batch [700/782]  Loss: 0.045638\n",
      "*** Epoch 2 Complete.  Avg Loss = 0.046098 ***\n",
      "Epoch [3/3]  Batch [100/782]  Loss: 0.045557\n",
      "Epoch [3/3]  Batch [200/782]  Loss: 0.045925\n",
      "Epoch [3/3]  Batch [300/782]  Loss: 0.045977\n",
      "Epoch [3/3]  Batch [400/782]  Loss: 0.045961\n",
      "Epoch [3/3]  Batch [500/782]  Loss: 0.046294\n",
      "Epoch [3/3]  Batch [600/782]  Loss: 0.045829\n",
      "Epoch [3/3]  Batch [700/782]  Loss: 0.045600\n",
      "*** Epoch 3 Complete.  Avg Loss = 0.045994 ***\n"
     ]
    }
   ],
   "source": [
    "train_scm(\n",
    "    model,\n",
    "    dataset,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0,\n",
    "    batch_size=128,\n",
    "    num_epochs=3,\n",
    "    schedule_length=3,\n",
    "    eps_max=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add108c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m texts = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhe asked her if she was hungry.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshe never heard that before.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mpipe\u001b[49m.generate(\n\u001b[32m      7\u001b[39m     texts,\n\u001b[32m      8\u001b[39m     n_future_steps = \u001b[32m5\u001b[39m,\n\u001b[32m      9\u001b[39m     sigma_noise = \u001b[32m0.0\u001b[39m,\n\u001b[32m     10\u001b[39m     temperature = \u001b[32m0.0\u001b[39m,\n\u001b[32m     11\u001b[39m     max_len = \u001b[32m30\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'he asked her if she was hungry.',\n",
    "    'she never heard that before.',\n",
    "]\n",
    "\n",
    "pipe.generate(\n",
    "    texts,\n",
    "    n_future_steps = 5,\n",
    "    sigma_noise = 0.0,\n",
    "    temperature = 0.0,\n",
    "    max_len = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = [dataset[i][0] for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "809386b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack(tensor_list)\n",
    "d = c.view(-1, 384)\n",
    "\n",
    "global_mean = d.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "61da6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-predictor MSE: 0.04862626641988754\n"
     ]
    }
   ],
   "source": [
    "# shift targets:\n",
    "X = c[:, :14, :]   # your input windows (ground truth)\n",
    "Y = c[:, 1:, :]    # “true” next embeddings\n",
    "\n",
    "n_total = float(Y.numel())\n",
    "baseline_mse = ((Y - global_mean.unsqueeze(0).unsqueeze(0))**2).sum() / n_total\n",
    "print(\"Mean-predictor MSE:\", baseline_mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5acc6e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 384])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.view(-1, 384).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

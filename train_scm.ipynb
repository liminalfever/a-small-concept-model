{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e09560",
   "metadata": {},
   "source": [
    "# SCM Training\n",
    "Here, we train a small concept model (SCM) for next-concept prediction. We will use the pre-trained PreNet to invert the embeddings into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bbe47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modules.inverter import build_inverter, get_encoder\n",
    "from modules.data import SCMTrainingDataset, get_bookcorpus_for_scm\n",
    "from modules.scm import SmallConceptModel, GenerativeSCM\n",
    "from modules.train import train_scm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d439b3",
   "metadata": {},
   "source": [
    "## Configs\n",
    "We define configs for model and training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04e1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    \"encoder_id\": \"BAAI/bge-m3\",\n",
    "}\n",
    "\n",
    "scm_configs = {\n",
    "    \"d_model\": 768,\n",
    "    \"embed_dim\": 1024,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 4 * 512,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 16,\n",
    "}\n",
    "\n",
    "train_configs = {\n",
    "    \"load_weights\": None,\n",
    "    \"save_weights\": \"saved_models/scm_v01_BGEM3.pth\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"max_target_len\": 64,\n",
    "    \"embed_batch_size\": 32,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"sample_data\": 0.03,\n",
    "    \"num_epochs\": 1,\n",
    "}\n",
    "\n",
    "data_configs = {\n",
    "    \"load_cached\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415798c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ca783",
   "metadata": {},
   "source": [
    "## Models\n",
    "We initialize and load the encoder, inverter, and SCM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0069958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder(models_config[\"encoder_id\"])\n",
    "inverter = build_inverter()\n",
    "scm = SmallConceptModel(**scm_configs).to(device)\n",
    "\n",
    "if train_configs[\"load_weights\"]:\n",
    "    scm.load_state_dict(torch.load(train_configs[\"load_weights\"], map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0056ce",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We load cached embeddings if available, otherwise we rebuild the dataloader via the `get_bookcorpus_for_scm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_configs[\"load_cached\"]:\n",
    "    embeddings = torch.load(data_configs[\"load_cached\"])\n",
    "    dataset = SCMTrainingDataset(embeddings)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=train_configs[\"train_batch_size\"],\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "else:\n",
    "    dataloader = get_bookcorpus_for_scm(\n",
    "        encoder,\n",
    "        train_configs[\"train_batch_size\"],\n",
    "        train_configs[\"embed_batch_size\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2540b642",
   "metadata": {},
   "source": [
    "## Training\n",
    "Finally, we can train the model using the `train_sm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scm(\n",
    "    scm,\n",
    "    dataloader,\n",
    "    scm_configs[\"max_seq_len\"],\n",
    "    train_configs[\"lr\"],\n",
    "    train_configs[\"weight_decay\"],\n",
    "    train_configs[\"num_epochs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474f5e5",
   "metadata": {},
   "source": [
    "Save the updated weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4669de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(scm.state_dict(), \"saved_models/scm_v01.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec2df2",
   "metadata": {},
   "source": [
    "## Inference\n",
    "We can test the model at inference time using the `GenerativeSCM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scm = GenerativeSCM(scm, encoder, inverter)\n",
    "\n",
    "sentences = [\n",
    "    \"this is a phd research proposal .\",\n",
    "    \"it is about neural networks .\"\n",
    "]\n",
    "\n",
    "gen_scm.generate(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a29cead",
   "metadata": {},
   "source": [
    "# Small Concept Model (SCM) Training\n",
    "Here, we train our `SmallConceptModel` for next-concept prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75e732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from small_concept_model.inverter import get_encoder\n",
    "from small_concept_model.data import SCMDataset, get_bookcorpus_scm\n",
    "from small_concept_model.model import SmallConceptModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f783e9",
   "metadata": {},
   "source": [
    "## Configs\n",
    "Here, we can specify some configuration parameters, such as the number of attention heads model we want to use for the `SmallLanguageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3134795",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_ID  : str = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "EMBED_BS    : int   = 128\n",
    "\n",
    "D_EMBED     : int   = 384\n",
    "D_MODEL     : int   = 512\n",
    "D_FF        : int   = 4 * D_MODEL\n",
    "N_LAYERS    : int   = 4\n",
    "N_HEADS     : int   = 8\n",
    "LOAD_WEIGHTS: str   = None\n",
    "\n",
    "NUM_EPOCHS  : int   = 10\n",
    "TRAIN_BS    : int   = 128\n",
    "LEARN_RATE  : float = 1e-3\n",
    "WEIGHT_DECAY: float = 1e-6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ff3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c0d82",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "To create the training dataset, we first need to get an encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b06d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(ENCODER_ID, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273af66",
   "metadata": {},
   "source": [
    "Now we can load and pre-process the dataset using the `get_bookcorpus_scm` function and wrap it into the `SCMDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_bookcorpus_scm(\n",
    "    encoder=encoder,\n",
    "    embed_batch_size=EMBED_BS,\n",
    "    clean=True\n",
    ")\n",
    "\n",
    "dataset = SCMDataset(embeddings)\n",
    "dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104883d9",
   "metadata": {},
   "source": [
    "Extract the average embedding vector for debugging during training, as predictions tend to collapse to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce609d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_embeds = embeddings.view(-1, embeddings.size(-1))\n",
    "mean_tensor = flat_embeds.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb76d9",
   "metadata": {},
   "source": [
    "## SCM Training\n",
    "First, we initialize our _SCM_ using the `SmallConceptModel` class and define the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e49c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallConceptModel(\n",
    "    d_embed=D_EMBED,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARN_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db486222",
   "metadata": {},
   "source": [
    "Finally, we perform the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67213b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    pos_sims = 0.0\n",
    "    sims_with_avg = 0.0\n",
    "\n",
    "    for idx, (batch_seq, batch_target) in tqdm(enumerate(transformer_dataloader), total=len(transformer_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_seq = batch_seq.to(device)\n",
    "        batch_target = batch_target.to(device)\n",
    "\n",
    "        preds = model(batch_seq)\n",
    "\n",
    "        pos_sims += F.cosine_similarity(preds, batch_target, dim=-1).mean().item()\n",
    "        sims_with_avg += F.cosine_similarity(preds, mean_tensor, dim=-1).mean().item()\n",
    "\n",
    "        random_embed = get_random_embed(transformer_dataset).to(device)\n",
    "        random_embed = random_embed.unsqueeze(0)\n",
    "\n",
    "        loss = criterion(preds, batch_target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * batch_seq.size(0)\n",
    "\n",
    "        if idx % 500 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}] - Batch [{idx + 1}/{len(transformer_dataloader)}] - Loss: {loss.item():.6f}\")\n",
    "\n",
    "    avg_loss = epoch_loss / len(transformer_dataset)\n",
    "    avg_pos_sim = pos_sims / len(transformer_dataloader)\n",
    "    avg_sims_with_avg = sims_with_avg / len(transformer_dataloader)\n",
    "\n",
    "    print(f\"*** Epoch [{epoch + 1}/{NUM_EPOCHS}] - Loss: {avg_loss:.6f} - Pos Sim: {avg_pos_sim:.6f} - Sim with Avg: {avg_sims_with_avg:.6f} ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776336d",
   "metadata": {},
   "source": [
    "Save the model's weights' checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_WEIGHTS: str = \"saved_models/test_scm_checkpoint\"\n",
    "\n",
    "if SAVE_WEIGHTS:\n",
    "    torch.save(prenet.state_dict(), SAVE_WEIGHTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
